import argparse
import torch
import torch.optim as optim
import numpy as np
from torch.utils.data import Subset, DataLoader

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆåŸºäºè®ºæ–‡ã€ŠGNNs Generalization Improvement...ã€‹å®ç°ï¼‰
from data_loader import SceneDataset, get_data_loader
from pretraining import GTransformerPretrain, pretrain_loop
from finetuning import GTransformerFinetune, finetune_loop
from physics_loss import PhysicsInformedLoss
from utils import calc_nrmse, calc_physics_satisfaction, generate_voltage_mask


def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆé€‚é…è®ºæ–‡é¢„è®­ç»ƒã€å¾®è°ƒã€æ¨ç†å…¨æµç¨‹ï¼ŒğŸ”¶1-20ã€ğŸ”¶1-113ã€ğŸ”¶1-140ï¼‰
    è¿”å›ï¼šè§£æåçš„å‚æ•°å¯¹è±¡
    """
    parser = argparse.ArgumentParser(description="åŸºäºè®ºæ–‡çš„é…ç”µç½‘æ½®æµè®¡ç®—GTransformeræ¨¡å‹ï¼ˆ20-50èŠ‚ç‚¹è¾å°„å‹ç½‘ç»œï¼‰")
    # æ ¸å¿ƒè¿è¡Œå‚æ•°
    parser.add_argument("--mode", type=str, default="finetune",
                        choices=["pretrain", "finetune", "infer"],
                        help="è¿è¡Œæ¨¡å¼ï¼špretrainï¼ˆé¢„è®­ç»ƒï¼‰ã€finetuneï¼ˆå¾®è°ƒï¼‰ã€inferï¼ˆæ¨ç†ï¼‰")
    parser.add_argument("--data_root", type=str, default="./Dataset",
                        help="æ•°æ®é›†æ ¹è·¯å¾„ï¼ˆé»˜è®¤ï¼š./Datasetï¼Œéœ€åŒ…å«Sence_1~Sence_100.npyï¼‰")
    parser.add_argument("--pretrain_path", type=str, default="./pretrained_weights.pth",
                        help="é¢„è®­ç»ƒæƒé‡ä¿å­˜/åŠ è½½è·¯å¾„ï¼ˆé»˜è®¤ï¼š./pretrained_weights.pthï¼‰")
    parser.add_argument("--finetune_path", type=str, default="./finetuned_weights.pth",
                        help="å¾®è°ƒæƒé‡ä¿å­˜/åŠ è½½è·¯å¾„ï¼ˆé»˜è®¤ï¼š./finetuned_weights.pthï¼‰")
    # æ•°æ®ä¸è®­ç»ƒå‚æ•°
    parser.add_argument("--mask_ratio", type=float, default=0.3,
                        help="ç”µå‹æ©ç æ¯”ä¾‹ï¼ˆä»…éå¹³è¡¡èŠ‚ç‚¹ï¼Œé»˜è®¤0.3ï¼ŒğŸ”¶1-78ï¼‰")
    parser.add_argument("--epochs", type=int, default=30,
                        help="è®­ç»ƒè½®æ¬¡ï¼ˆé¢„è®­ç»ƒé»˜è®¤50ï¼Œå¾®è°ƒé»˜è®¤30ï¼ŒğŸ”¶1-128ã€ğŸ”¶1-141ï¼‰")
    parser.add_argument("--batch_size", type=int, default=8,
                        help="Batchå¤§å°ï¼ˆé»˜è®¤8ï¼Œé€‚é…å°èŠ‚ç‚¹è§„æ¨¡GPUå†…å­˜ï¼‰")
    # æ¨ç†æ¨¡å¼ä¸“ç”¨å‚æ•°
    parser.add_argument("--scene_idx", type=int, default=None,
                        help="æ¨ç†æ¨¡å¼æŒ‡å®šåœºæ™¯ç¼–å·ï¼ˆ1~100ï¼Œé»˜è®¤ä½¿ç”¨æµ‹è¯•é›†5ä¸ªåœºæ™¯ï¼‰")

    args = parser.parse_args()
    # å‚æ•°åˆæ³•æ€§æ ¡éªŒï¼ˆè´´åˆè®ºæ–‡ä¸æ•°æ®é›†è¦æ±‚ï¼‰
    if args.mask_ratio < 0 or args.mask_ratio > 1:
        raise ValueError(f"æ©ç æ¯”ä¾‹mask_ratioéœ€åœ¨[0,1]èŒƒå›´å†…ï¼Œå½“å‰è¾“å…¥ï¼š{args.mask_ratio}ï¼ˆğŸ”¶1-78ï¼‰")
    if args.epochs < 1:
        raise ValueError(f"è®­ç»ƒè½®æ¬¡epochséœ€â‰¥1ï¼Œå½“å‰è¾“å…¥ï¼š{args.epochs}")
    if args.batch_size < 1:
        raise ValueError(f"Batchå¤§å°batch_sizeéœ€â‰¥1ï¼Œå½“å‰è¾“å…¥ï¼š{args.batch_size}")
    if args.scene_idx is not None and (args.scene_idx < 1 or args.scene_idx > 100):
        raise ValueError(f"åœºæ™¯ç¼–å·scene_idxéœ€åœ¨1~100èŒƒå›´å†…ï¼Œå½“å‰è¾“å…¥ï¼š{args.scene_idx}")
    return args


def load_data(args):
    """
    åŠ è½½æ•°æ®é›†å¹¶æŒ‰æ¨¡å¼æ‹†åˆ†ï¼ˆé€‚é…è®ºæ–‡æ•°æ®ä½¿ç”¨é€»è¾‘ï¼ŒğŸ”¶1-118ã€ğŸ”¶1-126ï¼‰
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡
    Returns:
        æ¨¡å¼å¯¹åº”çš„DataLoaderæˆ–æ•°æ®å­—å…¸ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰
    """
    print(f"=== åŠ è½½æ•°æ®é›†ï¼ˆè·¯å¾„ï¼š{args.data_root}ï¼Œæ¨¡å¼ï¼š{args.mode}ï¼‰===")
    # 1. åŠ è½½å®Œæ•´æ•°æ®é›†ï¼ˆ100ä¸ªåœºæ™¯ï¼‰
    full_dataset = SceneDataset(
        data_root=args.data_root,
        #mask_ratio=args.mask_ratio
    )
    total_scenes = len(full_dataset)
    print(f"å®Œæ•´æ•°æ®é›†åŠ è½½å®Œæˆï¼šå…±{total_scenes}ä¸ªåœºæ™¯ï¼ˆ20-50èŠ‚ç‚¹è¾å°„å‹ç½‘ç»œï¼‰")

    # 2. æŒ‰æ¨¡å¼æ‹†åˆ†æ•°æ®é›†
    if args.mode == "pretrain":
        # é¢„è®­ç»ƒï¼šä½¿ç”¨å…¨éƒ¨100ä¸ªåœºæ™¯ï¼ˆæ— éªŒè¯ï¼ŒğŸ”¶1-118ï¼‰
        train_loader = get_data_loader(
            data_root="./Dataset",
            batch_size=args.batch_size,
            shuffle=True,
            num_workers=2
        )
        print(f"é¢„è®­ç»ƒæ•°æ®é…ç½®ï¼šBatch={args.batch_size}ï¼Œåœºæ™¯æ•°={total_scenes}ï¼ˆå…¨é‡ï¼‰")
        return {"train_loader": train_loader}

    elif args.mode in ["finetune", "infer"]:
        # å¾®è°ƒ/æ¨ç†ï¼šæ‹†åˆ†80è®­ç»ƒ+15éªŒè¯+5æµ‹è¯•ï¼ˆğŸ”¶1-140æµ‹è¯•é€»è¾‘ï¼‰
        np.random.seed(42)  # å›ºå®šç§å­ç¡®ä¿å¯å¤ç°
        indices = np.random.permutation(total_scenes)
        train_indices = indices[:80]
        val_indices = indices[80:95]
        test_indices = indices[95:100]

        # æ„å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
        train_dataset = Subset(full_dataset, train_indices)
        val_dataset = Subset(full_dataset, val_indices)
        test_dataset = Subset(full_dataset, test_indices)

        # ç”ŸæˆDataLoader
        train_loader = get_data_loader(
            dataset=train_dataset,
            batch_size=args.batch_size,
            shuffle=True,
            num_workers=2
        )
        val_loader = get_data_loader(
            dataset=val_dataset,
            batch_size=args.batch_size,
            shuffle=False,
            num_workers=1
        )
        test_loader = get_data_loader(
            dataset=test_dataset,
            batch_size=1,  # æ¨ç†æ—¶å•åœºæ™¯å¤„ç†
            shuffle=False,
            num_workers=0
        )

        print(
            f"æ•°æ®é›†æ‹†åˆ†å®Œæˆï¼šè®­ç»ƒ{len(train_dataset)}ä¸ªåœºæ™¯ | éªŒè¯{len(val_dataset)}ä¸ªåœºæ™¯ | æµ‹è¯•{len(test_dataset)}ä¸ªåœºæ™¯")

        # æ¨ç†æ¨¡å¼ï¼šè‹¥æŒ‡å®šscene_idxï¼Œå•ç‹¬åŠ è½½è¯¥åœºæ™¯
        if args.mode == "infer" and args.scene_idx is not None:
            # åŠ è½½æŒ‡å®šåœºæ™¯ï¼ˆSence_{scene_idx}.npyï¼‰
            scene_file = f"{args.data_root}/Sence_{args.scene_idx}.npy"
            try:
                data = np.load(scene_file, allow_pickle=False)
                node_mat, line_mat, adj_mat = data[0], data[1], data[2]
                node_count = node_mat.shape[0]
                # ç”Ÿæˆæ©ç ï¼ˆåŒDataseté€»è¾‘ï¼‰
                mask = generate_voltage_mask(
                    node_count=node_count,
                    mask_ratio=args.mask_ratio,
                    balance_node_idx=1
                )
                # è½¬æ¢ä¸ºTensorå¹¶æ·»åŠ Batchç»´åº¦
                infer_data = {
                    "node_feat": torch.FloatTensor(node_mat) * (1 - mask),
                    "adj": torch.FloatTensor(adj_mat),
                    "line_param": torch.FloatTensor(line_mat),
                    "gt_node": torch.FloatTensor(node_mat),
                    "gt_line": torch.FloatTensor(line_mat),
                    "mask": mask,
                    "node_count": torch.tensor(node_count, dtype=torch.int32)
                }
                print(f"æ¨ç†æ¨¡å¼ï¼šå·²åŠ è½½æŒ‡å®šåœºæ™¯{args.scene_idx}ï¼ˆèŠ‚ç‚¹æ•°ï¼š{node_count}ï¼‰")
                return {"infer_data": infer_data, "test_loader": test_loader}
            except FileNotFoundError:
                raise FileNotFoundError(f"æŒ‡å®šåœºæ™¯æ–‡ä»¶ä¸å­˜åœ¨ï¼š{scene_file}")

        return {"train_loader": train_loader, "val_loader": val_loader, "test_loader": test_loader}


def init_model(args, device):
    """
    åˆå§‹åŒ–æ¨¡å‹ï¼ˆæ ¹æ®æ¨¡å¼é€‚é…è®ºæ–‡çš„GTransformerç»“æ„ï¼ŒğŸ”¶1-22ã€ğŸ”¶1-113ï¼‰
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡
        device: è®­ç»ƒ/æ¨ç†è®¾å¤‡ï¼ˆcpu/cudaï¼‰
    Returns:
        åˆå§‹åŒ–åçš„æ¨¡å‹å¯¹è±¡
    """
    # æ¨¡å‹æ ¸å¿ƒå‚æ•°ï¼ˆè´´åˆè®ºæ–‡å°èŠ‚ç‚¹é€‚é…é€»è¾‘ï¼ŒğŸ”¶1-128ï¼‰
    model_config = {
        "d_in": 4,  # èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ï¼ˆP_load, Q_load, V, Î¸ï¼‰
        "d_model": 64,  # åµŒå…¥ç»´åº¦ï¼ˆé€‚é…20-50èŠ‚ç‚¹ï¼‰
        "n_heads": 4,  # æ³¨æ„åŠ›å¤´æ•°ï¼ˆ64//4=16ï¼Œå•å¤´ç»´åº¦åˆç†ï¼‰
        "n_layers": 2  # GTransformerå±‚æ•°ï¼ˆé¿å…æ·±å±‚è¿‡æ‹Ÿåˆï¼‰
    }
    print(f"=== åˆå§‹åŒ–æ¨¡å‹ï¼ˆè®¾å¤‡ï¼š{device}ï¼Œå‚æ•°ï¼š{model_config}ï¼‰===")

    if args.mode == "pretrain":
        # é¢„è®­ç»ƒæ¨¡å‹ï¼šGTransformerPretrainï¼ˆğŸ”¶1-20ã€ğŸ”¶1-75ï¼‰
        model = GTransformerPretrain(
            d_in=model_config["d_in"],
            d_model=model_config["d_model"],
            n_heads=model_config["n_heads"],
            n_layers=model_config["n_layers"]
        ).to(device)
        print(f"é¢„è®­ç»ƒæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆå‚æ•°æ€»æ•°ï¼š{sum(p.numel() for p in model.parameters() if p.requires_grad):,}ï¼‰")
        return model

    elif args.mode in ["finetune", "infer"]:
        # å¾®è°ƒ/æ¨ç†æ¨¡å‹ï¼šGTransformerFinetuneï¼ˆåŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ŒğŸ”¶1-113ã€ğŸ”¶1-141ï¼‰
        try:
            model = GTransformerFinetune(
                pretrain_path=args.pretrain_path,
                d_in=model_config["d_in"],
                d_model=model_config["d_model"],
                n_heads=model_config["n_heads"],
                n_layers=model_config["n_layers"]
            ).to(device)
            # æ¨ç†æ¨¡å¼ï¼šåŠ è½½å¾®è°ƒæƒé‡
            if args.mode == "infer":
                if not torch.isfile(args.finetune_path):
                    raise FileNotFoundError(f"å¾®è°ƒæƒé‡æ–‡ä»¶ä¸å­˜åœ¨ï¼š{args.finetune_path}")
                model.load_state_dict(torch.load(args.finetune_path, map_location=device))
                model.eval()  # æ¨ç†æ¨¡å¼åˆ‡æ¢ä¸ºè¯„ä¼°æ¨¡å¼
                print(f"æ¨ç†æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼šå·²åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆ{args.pretrain_path}ï¼‰ä¸å¾®è°ƒæƒé‡ï¼ˆ{args.finetune_path}ï¼‰")
            else:
                print(f"å¾®è°ƒæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼šå·²åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆ{args.pretrain_path}ï¼‰")
            return model
        except FileNotFoundError as e:
            raise RuntimeError(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}") from e


def run_pretrain(args, data_dict, device):
    """
    æ‰§è¡Œé¢„è®­ç»ƒæµç¨‹ï¼ˆåŸºäºè®ºæ–‡è‡ªç›‘ç£æ©ç ç”µå‹é¢„æµ‹ï¼ŒğŸ”¶1-23ã€ğŸ”¶1-75ï¼‰
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡
        data_dict: æ•°æ®åŠ è½½ç»“æœï¼ˆå«train_loaderï¼‰
        device: è®­ç»ƒè®¾å¤‡
    """
    print("\n=== å¯åŠ¨é¢„è®­ç»ƒæµç¨‹ï¼ˆè®ºæ–‡PPGTæ¡†æ¶ç®€åŒ–ç‰ˆï¼ŒğŸ”¶1-20ï¼‰===")
    # 1. åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
    model = init_model(args, device)
    loss_fn = PhysicsInformedLoss(lambda_=0.5).to(device)  # ç‰©ç†çº¦æŸæƒé‡Î»=0.5ï¼ˆğŸ”¶1-82ï¼‰
    optimizer = optim.Adam(model.parameters(), lr=1e-3)  # å­¦ä¹ ç‡1e-3ï¼ˆğŸ”¶1-128ï¼‰

    # 2. è°ƒæ•´é¢„è®­ç»ƒè½®æ¬¡ï¼ˆé»˜è®¤50ï¼ŒğŸ”¶1-118ï¼‰
    pretrain_epochs = args.epochs if args.epochs != 30 else 50
    print(f"é¢„è®­ç»ƒé…ç½®ï¼šè½®æ¬¡={pretrain_epochs}ï¼ŒBatch={args.batch_size}ï¼ŒæŸå¤±å‡½æ•°=PhysicsInformedLossï¼ˆÎ»=0.5ï¼‰")

    # 3. å¯åŠ¨é¢„è®­ç»ƒ
    pretrain_loop(
        model=model,
        data_loader=data_dict["train_loader"],
        loss_fn=loss_fn,
        optimizer=optimizer,
        epochs=pretrain_epochs,
        device=device,
        save_path=args.pretrain_path
    )
    print("=== é¢„è®­ç»ƒæµç¨‹å®Œæˆï¼ˆæƒé‡å·²ä¿å­˜è‡³ï¼š{args.pretrain_path}ï¼‰===")


def run_finetune(args, data_dict, device):
    """
    æ‰§è¡Œå¾®è°ƒæµç¨‹ï¼ˆåŸºäºè®ºæ–‡é¢„è®­ç»ƒæƒé‡è¿ç§»ï¼ŒğŸ”¶1-113ã€ğŸ”¶1-140ï¼‰
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡
        data_dict: æ•°æ®åŠ è½½ç»“æœï¼ˆå«train_loaderã€val_loaderã€test_loaderï¼‰
        device: è®­ç»ƒè®¾å¤‡
    """
    print("\n=== å¯åŠ¨å¾®è°ƒæµç¨‹ï¼ˆèšç„¦ç”µå‹ç¼ºå¤±ä¸‹æ½®æµè®¡ç®—ï¼ŒğŸ”¶1-141ï¼‰===")
    # 1. åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
    model = init_model(args, device)
    loss_fn = PhysicsInformedLoss(lambda_=0.5).to(device)  # åŒé¢„è®­ç»ƒçš„ç‰©ç†çº¦æŸæƒé‡
    optimizer = optim.Adam(model.parameters(), lr=5e-4)  # å­¦ä¹ ç‡5e-4ï¼ˆå¼±äºé¢„è®­ç»ƒï¼Œä¿æŠ¤æƒé‡ï¼‰

    # 2. å¾®è°ƒé…ç½®ï¼ˆæ—©åœè€å¿ƒå€¼5ï¼Œè§£å†»è½®æ¬¡10ï¼ŒğŸ”¶1-141ï¼‰
    print(f"å¾®è°ƒé…ç½®ï¼šè½®æ¬¡={args.epochs}ï¼ŒBatch={args.batch_size}ï¼Œå­¦ä¹ ç‡=5e-4ï¼Œæ—©åœè€å¿ƒå€¼=5ï¼Œè§£å†»è½®æ¬¡=10")

    # 3. å¯åŠ¨å¾®è°ƒ
    finetune_loop(
        model=model,
        train_loader=data_dict["train_loader"],
        val_loader=data_dict["val_loader"],
        loss_fn=loss_fn,
        optimizer=optimizer,
        epochs=args.epochs,
        device=device,
        save_path=args.finetune_path,
        unfreeze_epoch=10,
        patience=5
    )
    print("=== å¾®è°ƒæµç¨‹å®Œæˆï¼ˆæœ€ä¼˜æƒé‡å·²ä¿å­˜è‡³ï¼š{args.finetune_path}ï¼‰===")


def run_infer(args, data_dict, device):
    """
    æ‰§è¡Œæ¨ç†æµç¨‹ï¼ˆè¯„ä¼°ç”µå‹ç¼ºå¤±ä¸‹çš„æ½®æµé¢„æµ‹æ•ˆæœï¼ŒğŸ”¶1-140ã€ğŸ”¶1-186ï¼‰
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡
        data_dict: æ•°æ®åŠ è½½ç»“æœï¼ˆå«infer_dataæˆ–test_loaderï¼‰
        device: æ¨ç†è®¾å¤‡
    """
    print("\n=== å¯åŠ¨æ¨ç†æµç¨‹ï¼ˆè¯„ä¼°20-50èŠ‚ç‚¹è¾å°„å‹ç½‘ç»œæ½®æµé¢„æµ‹ï¼‰===")
    # 1. åˆå§‹åŒ–æ¨¡å‹
    model = init_model(args, device)
    # 2. æ¨ç†æ•°æ®å‡†å¤‡ï¼ˆæŒ‡å®šåœºæ™¯æˆ–æµ‹è¯•é›†ï¼‰
    if "infer_data" in data_dict:
        # æ¨ç†æŒ‡å®šåœºæ™¯
        infer_scenes = [data_dict["infer_data"]]
        print(f"æ¨ç†æ•°æ®ï¼šæŒ‡å®šåœºæ™¯ï¼ˆèŠ‚ç‚¹æ•°ï¼š{infer_scenes[0]['node_count'].item()}ï¼‰")
    else:
        # æ¨ç†æµ‹è¯•é›†5ä¸ªåœºæ™¯
        infer_scenes = []
        with torch.no_grad():
            for batch in data_dict["test_loader"]:
                infer_scenes.append({
                    "node_feat": batch["node_feat"].to(device),
                    "adj": batch["adj"].to(device),
                    "line_param": [lp.to(device) for lp in batch["line_param"]],
                    "gt_node": batch["gt_node"].to(device),
                    "gt_line": batch["gt_line"].to(device),
                    "node_count": batch["node_count"].to(device)
                })
        print(f"æ¨ç†æ•°æ®ï¼šæµ‹è¯•é›†5ä¸ªåœºæ™¯ï¼ˆèŠ‚ç‚¹æ•°èŒƒå›´ï¼š20-50ï¼‰")

    # 3. æ‰§è¡Œæ¨ç†ä¸ç»“æœåˆ†æ
    total_metrics = {
        "node_v_nrmse": 0.0, "line_p_nrmse": 0.0,
        "power_satisfaction": 0.0, "voltage_satisfaction": 0.0
    }
    with torch.no_grad():
        for scene_idx, scene in enumerate(infer_scenes, 1):
            print(f"\n--- åœºæ™¯{scene_idx}æ¨ç†ç»“æœ ---")
            # 3.1 å‰å‘ä¼ æ’­ï¼ˆé¢„æµ‹èŠ‚ç‚¹ç”µå‹+çº¿è·¯æ½®æµï¼‰
            pred_node, pred_line = model(
                node_feat=scene["node_feat"],
                adj=scene["adj"],
                node_count=scene["node_count"],
                line_param=scene["line_param"]
            )
            # 3.2 æå–çœŸå®ä¸é¢„æµ‹æ•°æ®ï¼ˆæˆªæ–­å¡«å……èŠ‚ç‚¹ï¼‰
            node_count = scene["node_count"].item()
            line_count = len(pred_line[0]) if isinstance(pred_line, list) else pred_line.shape[1]
            # èŠ‚ç‚¹æ•°æ®ï¼ˆç”µå‹å¹…å€¼Vï¼šç¬¬2åˆ—ï¼Œç›¸è§’Î¸ï¼šç¬¬3åˆ—ï¼‰
            gt_v = scene["gt_node"][0, :node_count, 2]  # çœŸå®ç”µå‹å¹…å€¼
            pred_v = pred_node[0, :node_count, 2]  # é¢„æµ‹ç”µå‹å¹…å€¼
            gt_theta = scene["gt_node"][0, :node_count, 3]  # çœŸå®ç”µå‹ç›¸è§’
            pred_theta = pred_node[0, :node_count, 3]  # é¢„æµ‹ç”µå‹ç›¸è§’
            # çº¿è·¯æ•°æ®ï¼ˆæœ‰åŠŸPï¼šç¬¬2åˆ—ï¼Œæ— åŠŸQï¼šç¬¬3åˆ—ï¼‰
            gt_line_p = scene["gt_line"][0, :line_count, 2]  # çœŸå®çº¿è·¯æœ‰åŠŸ
            pred_line_p = pred_line[0][:, 2]  # é¢„æµ‹çº¿è·¯æœ‰åŠŸ
            gt_line_q = scene["gt_line"][0, :line_count, 3]  # çœŸå®çº¿è·¯æ— åŠŸ
            pred_line_q = pred_line[0][:, 3]  # é¢„æµ‹çº¿è·¯æ— åŠŸ

            # 3.3 æ‰“å°å…³é”®é¢„æµ‹ç»“æœï¼ˆå‰10ä¸ªèŠ‚ç‚¹ï¼Œå‰5æ¡çº¿è·¯ï¼‰
            print("1. èŠ‚ç‚¹ç”µå‹é¢„æµ‹ç»“æœï¼ˆæ ‡å¹ºå€¼ï¼‰ï¼š")
            print(f"{'èŠ‚ç‚¹ç¼–å·':<8} {'çœŸå®V':<10} {'é¢„æµ‹V':<10} {'çœŸå®Î¸(rad)':<12} {'é¢„æµ‹Î¸(rad)':<12}")
            print("-" * 56)
            show_node_num = min(10, node_count)
            for i in range(show_node_num):
                print(f"{i + 1:<8} {gt_v[i]:<10.4f} {pred_v[i]:<10.4f} {gt_theta[i]:<12.4f} {pred_theta[i]:<12.4f}")

            print("\n2. çº¿è·¯æ½®æµé¢„æµ‹ç»“æœï¼ˆæ ‡å¹ºå€¼ï¼‰ï¼š")
            print(f"{'çº¿è·¯ç¼–å·':<8} {'çœŸå®P':<10} {'é¢„æµ‹P':<10} {'çœŸå®Q':<10} {'é¢„æµ‹Q':<10}")
            print("-" * 48)
            show_line_num = min(5, line_count)
            for i in range(show_line_num):
                print(
                    f"{i + 1:<8} {gt_line_p[i]:<10.4f} {pred_line_p[i]:<10.4f} {gt_line_q[i]:<10.4f} {pred_line_q[i]:<10.4f}")

            # 3.4 è®¡ç®—åœºæ™¯æŒ‡æ ‡ï¼ˆğŸ”¶1-137ã€ğŸ”¶1-186ï¼‰
            # èŠ‚ç‚¹ç”µå‹NRMSE
            node_v_nrmse = calc_nrmse(
                pred=pred_v.unsqueeze(0).unsqueeze(-1),
                gt=gt_v.unsqueeze(0).unsqueeze(-1),
                node_count=torch.tensor([node_count], device=device)
            )
            # çº¿è·¯æœ‰åŠŸNRMSE
            line_p_nrmse = calc_nrmse(
                pred=pred_line_p.unsqueeze(0).unsqueeze(-1),
                gt=gt_line_p.unsqueeze(0).unsqueeze(-1),
                node_count=torch.tensor([line_count], device=device)
            )
            # åŠŸç‡å¹³è¡¡æ»¡è¶³ç‡ï¼ˆéå¹³è¡¡èŠ‚ç‚¹ï¼Œè¯¯å·®<2.5%ï¼‰
            pred_p_inj = -pred_node[0, 1:node_count, 0]  # éå¹³è¡¡èŠ‚ç‚¹P_inj=-P_load
            gt_p_sum = torch.zeros(node_count, device=device)
            line_pairs = model._get_line_node_mapping(scene["adj"][0], scene["node_count"][0])
            for line_idx, (i, j) in enumerate(line_pairs):
                p_ij = gt_line_p[line_idx]
                gt_p_sum[i] += p_ij
                gt_p_sum[j] -= p_ij
            p_err = torch.abs(pred_p_inj - gt_p_sum[1:node_count])
            power_satisfaction = (p_err < 0.025).float().mean().item()
            # ç”µå‹çº¦æŸæ»¡è¶³ç‡ï¼ˆæ ‡å¹ºå€¼0.95~1.05ï¼‰
            voltage_satisfaction = ((pred_v >= 0.95) & (pred_v <= 1.05)).float().mean().item()

            # 3.5 æ‰“å°åœºæ™¯æŒ‡æ ‡
            print(f"\n3. åœºæ™¯{scene_idx}è¯„ä¼°æŒ‡æ ‡ï¼š")
            print(f"èŠ‚ç‚¹ç”µå‹NRMSEï¼š{node_v_nrmse:.4f}")
            print(f"çº¿è·¯æœ‰åŠŸNRMSEï¼š{line_p_nrmse:.4f}")
            print(f"åŠŸç‡å¹³è¡¡çº¦æŸæ»¡è¶³ç‡ï¼š{power_satisfaction:.2%}")
            print(f"ç”µå‹çº¦æŸæ»¡è¶³ç‡ï¼š{voltage_satisfaction:.2%}")

            # 3.6 ç´¯è®¡æ€»æŒ‡æ ‡
            total_metrics["node_v_nrmse"] += node_v_nrmse / len(infer_scenes)
            total_metrics["line_p_nrmse"] += line_p_nrmse / len(infer_scenes)
            total_metrics["power_satisfaction"] += power_satisfaction / len(infer_scenes)
            total_metrics["voltage_satisfaction"] += voltage_satisfaction / len(infer_scenes)

    # 4. æ‰“å°æ•´ä½“æ¨ç†æŒ‡æ ‡
    print("\n=== æ¨ç†æµç¨‹å®Œæˆ | æ•´ä½“è¯„ä¼°æŒ‡æ ‡ï¼ˆæ‰€æœ‰åœºæ™¯å¹³å‡ï¼‰===")
    print(f"èŠ‚ç‚¹ç”µå‹NRMSEï¼š{total_metrics['node_v_nrmse']:.4f}")
    print(f"çº¿è·¯æœ‰åŠŸNRMSEï¼š{total_metrics['line_p_nrmse']:.4f}")
    print(f"åŠŸç‡å¹³è¡¡çº¦æŸæ»¡è¶³ç‡ï¼š{total_metrics['power_satisfaction']:.2%}")
    print(f"ç”µå‹çº¦æŸæ»¡è¶³ç‡ï¼š{total_metrics['voltage_satisfaction']:.2%}")
    print("=" * 60)


def main():
    """ä¸»å‡½æ•°ï¼šä¸²è”æ•°æ®åŠ è½½ã€æ¨¡å‹åˆå§‹åŒ–ã€æ¨¡å¼åˆ†æ”¯é€»è¾‘"""
    # 1. è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    # 2. è‡ªåŠ¨æ£€æµ‹è®¾å¤‡ï¼ˆğŸ”¶1-128ç¡¬ä»¶é€‚é…é€»è¾‘ï¼‰
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"=== è®¾å¤‡æ£€æµ‹å®Œæˆï¼šä½¿ç”¨{device}ï¼ˆè‹¥éœ€GPUåŠ é€Ÿï¼Œè¯·ç¡®ä¿PyTorchä¸CUDAå…¼å®¹ï¼‰===")
    # 3. åŠ è½½æ•°æ®
    data_dict = load_data(args)
    # 4. æŒ‰æ¨¡å¼æ‰§è¡Œå¯¹åº”æµç¨‹
    if args.mode == "pretrain":
        run_pretrain(args, data_dict, device)
    elif args.mode == "finetune":
        run_finetune(args, data_dict, device)
    elif args.mode == "infer":
        run_infer(args, data_dict, device)
    print("\n=== æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæ¯• ===")


if __name__ == "__main__":
    main()