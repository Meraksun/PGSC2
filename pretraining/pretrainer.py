import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from typing import List, Dict, Tuple, Optional
import numpy as np
import os
from tqdm import tqdm

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from gnn_layers import DyMPNLayer, GraphMultiHeadAttention
from utils import generate_voltage_mask

class SceneDataset(Dataset):
    """
    é…ç”µç½‘åœºæ™¯æ•°æ®é›†ï¼ˆé€‚é…20-50èŠ‚ç‚¹è¾å°„å‹ç½‘ç»œï¼‰
    æ¯ä¸ªåœºæ™¯åŒ…å«ï¼šèŠ‚ç‚¹ç‰¹å¾çŸ©é˜µã€çº¿è·¯ç‰¹å¾çŸ©é˜µã€é‚»æ¥çŸ©é˜µ
    """
    def __init__(self, data_root: str):
        self.data_root = data_root
        self.scene_files = [f for f in os.listdir(data_root) if f.startswith("Sence_") and f.endswith(".npz")]
        self.scene_files.sort(key=lambda x: int(x.split("_")[1].split(".")[0]))  # æŒ‰åœºæ™¯ç¼–å·æ’åº

    def __len__(self) -> int:
        return len(self.scene_files)

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """åŠ è½½å•ä¸ªåœºæ™¯æ•°æ®ï¼Œè¿”å›èŠ‚ç‚¹çŸ©é˜µã€çº¿è·¯çŸ©é˜µã€é‚»æ¥çŸ©é˜µå’Œåœºæ™¯ç¼–å·"""
        scene_file = self.scene_files[idx]
        scene_path = os.path.join(self.data_root, scene_file)
        data = np.load(scene_path, allow_pickle=False)
        
        # .npz æ–‡ä»¶éœ€è¦é€šè¿‡é”®åè®¿é—®ï¼Œå°è¯•å¤šç§å¯èƒ½çš„é”®å
        if 'node' in data.files:
            # å¦‚æœä½¿ç”¨å‘½åé”®ä¿å­˜ï¼šnode, line, adj
            node_matrix = data['node']
            line_matrix = data['line']
            adj_matrix = data['adj']
        elif 'arr_0' in data.files:
            # å¦‚æœä½¿ç”¨é»˜è®¤é”®ä¿å­˜ï¼šarr_0, arr_1, arr_2
            node_matrix = data['arr_0']
            line_matrix = data['arr_1']
            adj_matrix = data['arr_2']
        elif len(data.files) >= 3:
            # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼ŒæŒ‰å­—æ¯é¡ºåºå–å‰ä¸‰ä¸ª
            files = sorted(data.files)
            node_matrix = data[files[0]]
            line_matrix = data[files[1]]
            adj_matrix = data[files[2]]
        else:
            raise ValueError(f"æ— æ³•ä» {scene_file} ä¸­æå–3ä¸ªæ•°ç»„ï¼Œæ‰¾åˆ°çš„æ–‡ä»¶é”®ï¼š{data.files}")

        # è½¬æ¢ä¸ºTensor
        return {
            "node_matrix": torch.FloatTensor(node_matrix),
            "line_matrix": torch.FloatTensor(line_matrix),
            "adj_matrix": torch.FloatTensor(adj_matrix),
            "scene_idx": torch.tensor(int(scene_file.split("_")[1].split(".")[0]), dtype=torch.long),
            # æ–°å¢ï¼šå½“å‰åœºæ™¯çš„çœŸå®èŠ‚ç‚¹æ•°ï¼ˆèŠ‚ç‚¹çŸ©é˜µçš„è¡Œæ•°ï¼‰
            "node_count": torch.tensor(node_matrix.shape[0], dtype=torch.long)
        }

def get_data_loader(
        data_root: str = "./Dataset",
        dataset: Dataset = None,
        batch_size: int = 8,
        shuffle: bool = True,
        num_workers: int = 2
) -> DataLoader:
    """è·å–æ•°æ®é›†åŠ è½½å™¨ï¼Œæ”¯æŒè‡ªå®šä¹‰collate_fnå¤„ç†å˜é•¿èŠ‚ç‚¹æ•°"""
    if dataset is None:
        dataset = SceneDataset(data_root)

    def _collate_fn(batch: List[Dict]) -> Dict:
        """
        è‡ªå®šä¹‰Batchæ‹¼æ¥å‡½æ•°ï¼šå¤„ç†ä¸åŒèŠ‚ç‚¹æ•°çš„åœºæ™¯ï¼Œç”¨0å¡«å……è‡³Batchå†…æœ€å¤§èŠ‚ç‚¹æ•°
        æ–°å¢ï¼šè®¡ç®—æ¯ä¸ªåœºæ™¯çš„çœŸå®èŠ‚ç‚¹æ•°å¹¶æ·»åŠ åˆ°batchä¸­
        """
        max_nodes = max(item["node_matrix"].shape[0] for item in batch)
        max_lines = max(item["line_matrix"].shape[0] for item in batch)

        node_matrix_batch = []
        line_matrix_batch = []
        adj_matrix_batch = []
        scene_idx_batch = []
        node_count_batch = []  # å­˜å‚¨æ¯ä¸ªåœºæ™¯çš„çœŸå®èŠ‚ç‚¹æ•°

        for item in batch:
            a = item["node_matrix"].shape[0]  # çœŸå®èŠ‚ç‚¹æ•°ï¼ˆå½“å‰åœºæ™¯ï¼‰
            b = item["line_matrix"].shape[0]
            adj_shape = item["adj_matrix"].shape  # é‚»æ¥çŸ©é˜µçš„å®é™…å½¢çŠ¶

            # èŠ‚ç‚¹çŸ©é˜µå¡«å……
            node_pad = torch.zeros(max_nodes, 4, dtype=item["node_matrix"].dtype)
            node_pad[:a] = item["node_matrix"]
            node_matrix_batch.append(node_pad)

            # çº¿è·¯çŸ©é˜µå¡«å……
            line_pad = torch.zeros(max_lines, 4, dtype=item["line_matrix"].dtype)
            line_pad[:b] = item["line_matrix"]
            line_matrix_batch.append(line_pad)

            # é‚»æ¥çŸ©é˜µå¡«å……
            adj_pad = torch.zeros(max_nodes, max_nodes, dtype=item["adj_matrix"].dtype)
            # ä½¿ç”¨å®é™…é‚»æ¥çŸ©é˜µå¤§å°å’ŒèŠ‚ç‚¹çŸ©é˜µå¤§å°çš„è¾ƒå°å€¼ï¼Œé¿å…ç»´åº¦ä¸åŒ¹é…
            adj_size = min(a, adj_shape[0], adj_shape[1])
            adj_pad[:adj_size, :adj_size] = item["adj_matrix"][:adj_size, :adj_size]
            adj_matrix_batch.append(adj_pad)

            # æ”¶é›†åœºæ™¯ç¼–å·å’ŒçœŸå®èŠ‚ç‚¹æ•°
            scene_idx_batch.append(item["scene_idx"])
            node_count_batch.append(a)  # è®°å½•å½“å‰åœºæ™¯çš„çœŸå®èŠ‚ç‚¹æ•°

        return {
            "node_matrix": torch.stack(node_matrix_batch),
            "line_matrix": torch.stack(line_matrix_batch),
            "adj_matrix": torch.stack(adj_matrix_batch),
            "scene_idx": torch.tensor(scene_idx_batch, dtype=torch.long),
            "node_count": torch.tensor(node_count_batch, dtype=torch.long)  # æ–°å¢ï¼šçœŸå®èŠ‚ç‚¹æ•°
        }

    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        collate_fn=_collate_fn
    )


class GTransformerPretrain(nn.Module):
    """
    åŸºäºGTransformerçš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆé€‚é…20-50èŠ‚ç‚¹è¾å°„å‹é…ç”µç½‘ï¼‰
    æ ¸å¿ƒç›®æ ‡ï¼šä»ç”µå‹ç¼ºå¤±çš„èŠ‚ç‚¹ç‰¹å¾ä¸­é¢„æµ‹å®Œæ•´èŠ‚ç‚¹ç”µå‹ï¼ˆè‡ªç›‘ç£å­¦ä¹ ï¼‰
    è®ºæ–‡é€»è¾‘é€‚é…ï¼šDyMPN + GraphMultiHeadAttention + èŠ‚ç‚¹é¢„æµ‹å¤´ï¼ˆğŸ”¶1-20ã€ğŸ”¶1-75ï¼‰
    """

    def __init__(
            self,
            d_in: int = 4,
            d_model: int = 64,
            n_heads: int = 4,
            n_layers: int = 2
    ):
        """
        åˆå§‹åŒ–é¢„è®­ç»ƒæ¨¡å‹

        Args:
            d_in: è¾“å…¥èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ï¼ˆé»˜è®¤4ï¼Œå¯¹åº”P_loadã€Q_loadã€Vã€Î¸ï¼‰
            d_model: åµŒå…¥/ä¸­é—´ç‰¹å¾ç»´åº¦ï¼ˆé»˜è®¤64ï¼Œé€‚é…20-50èŠ‚ç‚¹ï¼‰
            n_heads: æ³¨æ„åŠ›å¤´æ•°ï¼ˆé»˜è®¤4ï¼Œéœ€æ»¡è¶³d_model % n_heads == 0ï¼‰
            n_layers: GTransformerå †å å±‚æ•°ï¼ˆé»˜è®¤2ï¼Œé¿å…æ·±å±‚è¿‡æ‹Ÿåˆï¼‰
        """
        super().__init__()
        self.d_in = d_in
        self.d_model = d_model
        self.n_heads = n_heads
        self.n_layers = n_layers

        # 1. æ„å»ºn_layerså±‚GTransformerï¼ˆDyMPN + GraphMultiHeadAttentionï¼‰
        self.gtransformer_layers = nn.ModuleList()
        for i in range(n_layers):
            layer_dict = nn.ModuleDict({
                "dympn": DyMPNLayer(d_in=d_in if i == 0 else d_model, d_model=d_model),
                "gatt": GraphMultiHeadAttention(d_model=d_model, n_heads=n_heads, dropout=0.1)
            })
            self.gtransformer_layers.append(layer_dict)

        # 2. èŠ‚ç‚¹ç‰¹å¾é¢„æµ‹å¤´ï¼šå°†d_modelç»´ç‰¹å¾æ˜ å°„å›4ç»´ï¼ˆP_load, Q_load, V, Î¸ï¼‰
        self.node_pred_head = nn.Linear(d_model, d_in)

    def forward(
            self,
            node_feat: torch.Tensor,
            adj: torch.Tensor,
            node_count: torch.Tensor
    ) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­ï¼šä»æ©ç èŠ‚ç‚¹ç‰¹å¾é¢„æµ‹å®Œæ•´èŠ‚ç‚¹ç‰¹å¾ï¼ˆè®ºæ–‡ğŸ”¶1-75é¢„è®­ç»ƒé€»è¾‘ï¼‰

        Args:
            node_feat: å¸¦æ©ç çš„è¾“å…¥èŠ‚ç‚¹ç‰¹å¾ï¼ˆB, N, 4ï¼‰ï¼ŒB=Batchï¼ŒN=æœ€å¤§èŠ‚ç‚¹æ•°
            adj: æ‹“æ‰‘é‚»æ¥çŸ©é˜µï¼ˆB, N, Nï¼‰
            node_count: æ¯ä¸ªåœºæ™¯çš„çœŸå®èŠ‚ç‚¹æ•°ï¼ˆB, ï¼‰

        Returns:
            pred_node: é¢„æµ‹çš„å®Œæ•´èŠ‚ç‚¹ç‰¹å¾ï¼ˆB, N, 4ï¼‰
        """
        batch_size, max_node, _ = node_feat.shape
        h = node_feat

        # æ­¥éª¤1ï¼šé€šè¿‡n_layerså±‚GTransformeræå–ç‰¹å¾
        for layer in self.gtransformer_layers:
            # 1.1 DyMPNï¼šæå–å±€éƒ¨æ‹“æ‰‘ç‰¹å¾
            h = layer["dympn"](node_feat=h, adj=adj, node_count=node_count)
            # 1.2 GraphMultiHeadAttentionï¼šæ•æ‰å…¨å±€æ‹“æ‰‘ä¾èµ–
            # ç”Ÿæˆç”µå‹æ©ç ï¼ˆç”¨äºæ³¨æ„åŠ›å±‚çš„æ©ç å¤„ç†ï¼‰
            mask = torch.zeros(batch_size, max_node, 2, device=node_feat.device)
            for b in range(batch_size):
                real_node = node_count[b].item()
                # æ£€æŸ¥å“ªäº›èŠ‚ç‚¹çš„ç”µå‹è¢«æ©ç ï¼ˆnode_featä¸­Vã€Î¸ä¸º0çš„ä½ç½®ï¼‰
                # ç®€å•åˆ¤æ–­ï¼šå¦‚æœèŠ‚ç‚¹ç‰¹å¾çš„ç¬¬2ã€3åˆ—ï¼ˆVã€Î¸ï¼‰æ¥è¿‘0ï¼Œåˆ™è®¤ä¸ºè¢«æ©ç 
                v_theta = node_feat[b, :real_node, 2:4]
                is_masked = (torch.abs(v_theta) < 1e-6).any(dim=-1)  # (real_node,)
                mask[b, :real_node, 0] = is_masked.float()
                mask[b, :real_node, 1] = is_masked.float()
            h = layer["gatt"](h=h, mask=mask, node_count=node_count)

        # æ­¥éª¤2ï¼šèŠ‚ç‚¹ç‰¹å¾é¢„æµ‹ï¼ˆ4ç»´è¾“å‡ºï¼‰
        pred_node = self.node_pred_head(h)  # (B, N, 4)

        # æ­¥éª¤3ï¼šæˆªæ–­å¡«å……èŠ‚ç‚¹ï¼ˆé¿å…æ— æ•ˆæ•°æ®å¹²æ‰°ï¼‰
        # ä½¿ç”¨æ©ç æ“ä½œé¿å…åŸåœ°ä¿®æ”¹ï¼ˆä¿æŠ¤è®¡ç®—å›¾ï¼‰
        node_indices = torch.arange(max_node, device=pred_node.device).unsqueeze(0).expand(batch_size, -1)  # (B, N)
        node_count_expanded = node_count.unsqueeze(1).expand(-1, max_node)  # (B, N)
        pad_mask = node_indices >= node_count_expanded  # (B, N)ï¼ŒTrueè¡¨ç¤ºå¡«å……èŠ‚ç‚¹
        pred_node = pred_node.masked_fill(pad_mask.unsqueeze(-1), 0.0)

        return pred_node


def pretrain_loop(
        model: GTransformerPretrain,
        data_loader: DataLoader,
        loss_fn,
        optimizer: optim.Optimizer,
        epochs: int = 50,
        device: Optional[torch.device] = None,
        save_path: str = "./pretrained_weights.pth",
        mask_ratio: float = 0.3
) -> None:
    """
    é…ç”µç½‘æ½®æµè®¡ç®—ä»»åŠ¡é¢„è®­ç»ƒå¾ªç¯ï¼ˆè‡ªç›‘ç£æ©ç ç”µå‹é¢„æµ‹ï¼‰
    è®ºæ–‡é€»è¾‘é€‚é…ï¼šæ©ç ç”µå‹é¢„æµ‹ + ç‰©ç†çº¦æŸç›‘ç£ï¼ˆğŸ”¶1-20ã€ğŸ”¶1-75ã€ğŸ”¶1-82ã€ğŸ”¶1-118ï¼‰

    Args:
        model: GTransformerPretrainå®ä¾‹
        data_loader: è®­ç»ƒé›†DataLoaderï¼ˆ100ä¸ªåœºæ™¯ï¼‰
        loss_fn: ç‰©ç†çŸ¥æƒ…æŸå¤±å‡½æ•°ï¼ˆç¡®ä¿é¢„æµ‹ç¬¦åˆç‰©ç†è§„å¾‹ï¼‰
        optimizer: Adamä¼˜åŒ–å™¨ï¼ˆlr=1e-3ï¼Œè®ºæ–‡æ¨èï¼‰
        epochs: é¢„è®­ç»ƒè½®æ¬¡ï¼ˆé»˜è®¤50ï¼‰
        device: è®­ç»ƒè®¾å¤‡ï¼ˆè‡ªåŠ¨æ£€æµ‹cpu/cudaï¼‰
        save_path: é¢„è®­ç»ƒæƒé‡ä¿å­˜è·¯å¾„
        mask_ratio: ç”µå‹æ©ç æ¯”ä¾‹ï¼ˆé»˜è®¤0.3ï¼Œä»…éå¹³è¡¡èŠ‚ç‚¹ï¼‰
    """
    # 1. è®¾å¤‡è‡ªåŠ¨æ£€æµ‹ä¸æ¨¡å‹éƒ¨ç½²
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    loss_fn.to(device)
    print(f"=== å¼€å§‹é¢„è®­ç»ƒ | è®¾å¤‡: {device} | æ€»è½®æ¬¡: {epochs} | æ©ç æ¯”ä¾‹: {mask_ratio} ===")

    # 2. é¢„è®­ç»ƒä¸»å¾ªç¯
    for epoch in range(1, epochs + 1):
        model.train()
        train_metrics = {
            "total_loss": 0.0, "pred_loss": 0.0, "physics_loss": 0.0
        }
        total_samples = 0

        with tqdm(data_loader, desc=f"Epoch {epoch}/{epochs} (Pretrain)", unit="batch") as pbar:
            for batch in pbar:
                # 2.1 æ•°æ®å‡†å¤‡
                node_matrix = batch["node_matrix"].to(device)  # (B, N, 4)
                line_matrix = batch["line_matrix"].to(device)  # (B, L, 4)
                adj = batch["adj_matrix"].to(device)  # (B, N, N)
                node_count = batch["node_count"].to(device)  # (B,)
                batch_size = node_matrix.shape[0]

                # 2.2 ç”Ÿæˆç”µå‹æ©ç å¹¶åº”ç”¨åˆ°èŠ‚ç‚¹ç‰¹å¾
                node_feat_list = []
                mask_list = []
                line_param_list = []
                gt_line_list = []

                for b in range(batch_size):
                    real_node = node_count[b].item()
                    real_line = line_matrix.shape[1]  # çº¿è·¯æ•°

                    # ç”Ÿæˆæ©ç ï¼ˆä»…éå¹³è¡¡èŠ‚ç‚¹ï¼‰
                    mask = generate_voltage_mask(
                        node_count=real_node,
                        mask_ratio=mask_ratio,
                        balance_node_idx=1
                    ).to(device)

                    # åº”ç”¨æ©ç åˆ°èŠ‚ç‚¹ç‰¹å¾ï¼ˆmask: 1=æ©ç ï¼Œ0=ä¿ç•™ï¼‰
                    node_feat_b = node_matrix[b, :real_node, :] * (1 - mask)
                    node_feat_list.append(node_feat_b)

                    # æ”¶é›†æ©ç ç”¨äºåç»­å¤„ç†
                    mask_pad = torch.zeros(node_matrix.shape[1], 4, device=device)
                    mask_pad[:real_node, :] = mask
                    mask_list.append(mask_pad)

                    # å‡†å¤‡çº¿è·¯æ•°æ®ï¼ˆç”¨äºæŸå¤±è®¡ç®—ï¼‰
                    line_param_b = line_matrix[b, :real_line, :].clone()
                    line_param_list.append(line_param_b)

                    gt_line_b = line_matrix[b, :real_line, :].clone()
                    gt_line_list.append(gt_line_b)

                # å¡«å……èŠ‚ç‚¹ç‰¹å¾åˆ°ç»Ÿä¸€ç»´åº¦
                max_node = node_matrix.shape[1]
                node_feat = torch.zeros(batch_size, max_node, 4, device=device)
                for b, feat_b in enumerate(node_feat_list):
                    real_node = node_count[b].item()
                    node_feat[b, :real_node, :] = feat_b

                # 2.3 å‰å‘ä¼ æ’­ï¼šé¢„æµ‹å®Œæ•´èŠ‚ç‚¹ç‰¹å¾
                pred_node = model(
                    node_feat=node_feat,
                    adj=adj,
                    node_count=node_count
                )

                # 2.4 ä»é¢„æµ‹èŠ‚ç‚¹ç‰¹å¾ç”Ÿæˆçº¿è·¯æ½®æµé¢„æµ‹ï¼ˆç”¨äºç‰©ç†æŸå¤±è®¡ç®—ï¼‰
                # ç®€åŒ–å¤„ç†ï¼šä½¿ç”¨ä¸€ä¸ªç®€å•çš„çº¿æ€§å±‚ä»èŠ‚ç‚¹ç‰¹å¾é¢„æµ‹çº¿è·¯æ½®æµ
                # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨çœŸå®çº¿è·¯å‚æ•°ï¼ˆR, Xï¼‰ï¼Œä»…é¢„æµ‹Pã€Q
                pred_line_list = []
                for b in range(batch_size):
                    real_node = node_count[b].item()
                    line_param_b = line_param_list[b]  # (L, 4): R, X, P, Q
                    real_line = line_param_b.shape[0]

                    # ä»é‚»æ¥çŸ©é˜µè·å–çº¿è·¯-èŠ‚ç‚¹å¯¹æ˜ å°„
                    adj_b = adj[b, :real_node, :real_node]
                    line_pairs = []
                    for i in range(real_node):
                        for j in range(i + 1, real_node):
                            if adj_b[i, j] != 0:
                                line_pairs.append((i, j))

                    # ç®€å•çš„çº¿è·¯æ½®æµé¢„æµ‹ï¼šä½¿ç”¨è¿æ¥èŠ‚ç‚¹çš„å¹³å‡ç‰¹å¾é¢„æµ‹Pã€Q
                    pred_line_b = line_param_b.clone()  # ä¿ç•™Rã€X
                    for line_idx, (i, j) in enumerate(line_pairs[:real_line]):
                        # ä½¿ç”¨èŠ‚ç‚¹ç‰¹å¾çš„ç®€å•ç»„åˆé¢„æµ‹Pã€Qï¼ˆè¿™é‡Œç”¨ç®€åŒ–æ–¹æ³•ï¼‰
                        node_feat_i = pred_node[b, i, :]
                        node_feat_j = pred_node[b, j, :]
                        # ç®€å•çš„é¢„æµ‹ï¼šä½¿ç”¨Vå·®å€¼å’ŒP_loadå·®å€¼ä½œä¸ºPã€Qçš„ç²—ç•¥ä¼°è®¡
                        v_diff = node_feat_i[2] - node_feat_j[2]  # ç”µå‹å·®
                        p_diff = node_feat_i[0] - node_feat_j[0]  # è´Ÿè·å·®
                        # ç®€åŒ–çš„çº¿è·¯æ½®æµé¢„æµ‹ï¼ˆå®é™…åº”è¯¥ç”¨æ›´å¤æ‚çš„å…¬å¼ï¼‰
                        pred_line_b[line_idx, 2] = v_diff * 0.1 + p_diff  # é¢„æµ‹P
                        pred_line_b[line_idx, 3] = v_diff * 0.05  # é¢„æµ‹Qï¼ˆç®€åŒ–ï¼‰

                    pred_line_list.append(pred_line_b)

                # 2.5 è®¡ç®—æŸå¤±ï¼ˆç‰©ç†çŸ¥æƒ…æŸå¤±ï¼‰
                total_loss, pred_loss, physics_loss = loss_fn(
                    pred_node=pred_node,
                    gt_node=node_matrix,
                    pred_line=pred_line_list,
                    gt_line=gt_line_list,
                    adj=adj,
                    line_param=line_param_list,
                    node_count=node_count
                )

                # 2.6 åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°
                optimizer.zero_grad()
                total_loss.backward()
                optimizer.step()

                # 2.7 ç´¯è®¡æŒ‡æ ‡
                train_metrics["total_loss"] += total_loss.item() * batch_size
                train_metrics["pred_loss"] += pred_loss.item() * batch_size
                train_metrics["physics_loss"] += physics_loss.item() * batch_size
                total_samples += batch_size

                # è¿›åº¦æ¡æ›´æ–°
                pbar.set_postfix({
                    "æ€»æŸå¤±": f"{total_loss.item():.6f}",
                    "é¢„æµ‹æŸå¤±": f"{pred_loss.item():.6f}",
                    "ç‰©ç†æŸå¤±": f"{physics_loss.item():.6f}"
                })

        # 3. è®­ç»ƒæŒ‡æ ‡å¹³å‡åŒ–
        train_metrics = {k: v / total_samples for k, v in train_metrics.items()}
        print(f"\nğŸ“Š Epoch {epoch} é¢„è®­ç»ƒæŒ‡æ ‡ï¼š")
        print(
            f"   æ€»æŸå¤±: {train_metrics['total_loss']:.6f} | "
            f"é¢„æµ‹æŸå¤±: {train_metrics['pred_loss']:.6f} | "
            f"ç‰©ç†æŸå¤±: {train_metrics['physics_loss']:.6f}"
        )

        # 4. ä¿å­˜æƒé‡ï¼ˆæ¯ä¸ªepochéƒ½ä¿å­˜ï¼Œè¦†ç›–ä¹‹å‰ï¼‰
        torch.save(model.state_dict(), save_path)
        if epoch % 10 == 0:
            print(f"âœ… æƒé‡å·²ä¿å­˜è‡³: {save_path}ï¼ˆEpoch {epoch}ï¼‰")

    print(f"\nğŸ‰ é¢„è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæƒé‡å·²ä¿å­˜è‡³: {save_path}")