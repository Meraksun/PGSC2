import torch
import torch.nn as nn
import torch.optim as optim
from typing import Optional, Dict, List, Tuple
from torch.utils.data import DataLoader, Subset
import numpy as np
from tqdm import tqdm

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆåŸºäºè®ºæ–‡åŠå‰æ–‡å®ç°ï¼‰
from pretraining import GTransformerPretrain
from physics_loss import PhysicsInformedLoss
from utils import calc_nrmse, calc_physics_satisfaction  # è¯„ä¼°æŒ‡æ ‡ï¼ˆè®ºæ–‡ğŸ”¶1-137æŒ‡æ ‡é€‚é…ï¼‰


class GTransformerFinetune(nn.Module):
    """
    åŸºäºé¢„è®­ç»ƒGTransformerçš„å¾®è°ƒæ¨¡å‹ï¼ˆé€‚é…ç”¨æˆ·20-50èŠ‚ç‚¹è¾å°„å‹é…ç”µç½‘ï¼‰
    æ ¸å¿ƒç›®æ ‡ï¼šä»ç”µå‹ç¼ºå¤±çš„èŠ‚ç‚¹ç‰¹å¾ä¸­é¢„æµ‹å®Œæ•´æ½®æµï¼ˆèŠ‚ç‚¹ç”µå‹+çº¿è·¯æ½®æµï¼‰
    è®ºæ–‡é€»è¾‘é€‚é…ï¼šé¢„è®­ç»ƒæƒé‡è¿ç§»+ä¸‹æ¸¸ä»»åŠ¡ä¸“ç”¨é¢„æµ‹å¤´ï¼ˆğŸ”¶1-113ã€ğŸ”¶1-140ï¼‰
    """

    def __init__(
            self,
            pretrain_path: str,
            d_in: int = 4,
            d_model: int = 64,
            n_heads: int = 4,
            n_layers: int = 2
    ):
        """
        åˆå§‹åŒ–å¾®è°ƒæ¨¡å‹ï¼šåŠ è½½é¢„è®­ç»ƒæƒé‡+æ–°å¢çº¿è·¯æ½®æµé¢„æµ‹å¤´

        Args:
            pretrain_path: é¢„è®­ç»ƒGTransformeræƒé‡è·¯å¾„ï¼ˆ.pthæ–‡ä»¶ï¼‰
            d_in: è¾“å…¥èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ï¼ˆé»˜è®¤4ï¼ŒåŒé¢„è®­ç»ƒï¼‰
            d_model: åµŒå…¥/ä¸­é—´ç‰¹å¾ç»´åº¦ï¼ˆé»˜è®¤64ï¼ŒåŒé¢„è®­ç»ƒï¼‰
            n_heads: æ³¨æ„åŠ›å¤´æ•°ï¼ˆé»˜è®¤4ï¼ŒåŒé¢„è®­ç»ƒï¼‰
            n_layers: GTransformerå †å å±‚æ•°ï¼ˆé»˜è®¤2ï¼ŒåŒé¢„è®­ç»ƒï¼‰

        Raises:
            FileNotFoundError: é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ä¸å­˜åœ¨æ—¶æŠ›å‡º
        """
        super().__init__()
        # 1. åˆå§‹åŒ–é¢„è®­ç»ƒGTransformeréª¨å¹²ç½‘ç»œï¼ˆå¤ç”¨é¢„è®­ç»ƒç‰¹å¾æå–èƒ½åŠ›ï¼‰
        self.backbone = GTransformerPretrain(
            d_in=d_in,
            d_model=d_model,
            n_heads=n_heads,
            n_layers=n_layers
        )

        # 2. åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆä»…åŠ è½½ä¸backboneåŒ¹é…çš„å‚æ•°ï¼Œå¿½ç•¥çº¿è·¯é¢„æµ‹å¤´å‚æ•°ï¼‰
        if not torch.isfile(pretrain_path):
            raise FileNotFoundError(f"é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ä¸å­˜åœ¨ï¼š{pretrain_path}")
        pretrain_state = torch.load(pretrain_path, map_location="cpu")
        # è¿‡æ»¤æƒé‡ï¼šä»…ä¿ç•™backboneä¸­å­˜åœ¨çš„å‚æ•°ï¼ˆæ’é™¤çº¿è·¯é¢„æµ‹å¤´çš„éšæœºåˆå§‹åŒ–å‚æ•°ï¼‰
        backbone_state = {
            k: v for k, v in pretrain_state.items()
            if k in self.backbone.state_dict()
        }
        self.backbone.load_state_dict(backbone_state, strict=False)
        print(f"âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæƒé‡ï¼šå…±åŠ è½½{len(backbone_state)}/{len(pretrain_state)}ä¸ªå‚æ•°")

        # 3. æ–°å¢çº¿è·¯æ½®æµé¢„æµ‹å¤´ï¼ˆè®ºæ–‡ğŸ”¶1-113ï¼šä¸‹æ¸¸ä»»åŠ¡ä¸“ç”¨é¢„æµ‹å±‚ï¼‰
        # è®¾è®¡é€»è¾‘ï¼šè¾å°„å‹ç½‘ç»œçº¿è·¯æ•°b = N-1ï¼ˆNä¸ºèŠ‚ç‚¹æ•°ï¼‰ï¼Œå…ˆå¯¹èŠ‚ç‚¹ç‰¹å¾åš"çº¿è·¯çº§èšåˆ"
        # èšåˆæ–¹å¼ï¼šå¯¹æ¯æ¡çº¿è·¯è¿æ¥çš„ä¸¤ä¸ªèŠ‚ç‚¹ç‰¹å¾å–å¹³å‡ï¼Œå¾—åˆ°çº¿è·¯çº§ç‰¹å¾ï¼ˆb, d_modelï¼‰
        self.line_agg = lambda node_feat, line_node_mapping: torch.stack([
            (node_feat[:, i, :] + node_feat[:, j, :]) / 2  # (B, d_model)
            for i, j in line_node_mapping
        ], dim=1)  # è¾“å‡ºï¼š(B, b, d_model)
        # çº¿è·¯æ½®æµé¢„æµ‹å±‚ï¼šè¾“å…¥çº¿è·¯çº§ç‰¹å¾ï¼Œè¾“å‡º4ç»´æ½®æµï¼ˆR/Xç”¨çœŸå®å€¼ï¼Œä»…P/Qç”Ÿæ•ˆï¼‰
        self.line_pred_head = nn.Linear(d_model, 4)

    def _get_line_node_mapping(self, adj: torch.Tensor, node_count: torch.Tensor) -> List[Tuple[int, int]]:
        """
        è¾…åŠ©å‡½æ•°ï¼šåŸºäºé‚»æ¥çŸ©é˜µè·å–çº¿è·¯-èŠ‚ç‚¹å¯¹æ˜ å°„ï¼ˆé€‚é…è¾å°„å‹ç½‘ç»œb=N-1ï¼‰
        åŒç‰©ç†æŸå¤±å‡½æ•°ä¸­çš„çº¿è·¯æ˜ å°„é€»è¾‘ï¼ˆç¡®ä¿ä¸€è‡´æ€§ï¼ŒğŸ”¶1-88ï¼‰

        Args:
            adj: å•ä¸ªåœºæ™¯çš„é‚»æ¥çŸ©é˜µï¼ˆN, Nï¼‰
            node_count: å•ä¸ªåœºæ™¯çš„çœŸå®èŠ‚ç‚¹æ•°ï¼ˆintï¼‰

        Returns:
            line_node_mapping: çº¿è·¯-èŠ‚ç‚¹å¯¹åˆ—è¡¨ï¼ˆ[(i1,j1), (i2,j2), ...]ï¼Œi<jï¼‰
        """
        real_node = node_count.item()
        adj_trim = adj[:real_node, :real_node]
        line_pairs = []
        for i in range(real_node):
            for j in range(i + 1, real_node):
                if adj_trim[i, j] != 0:  # è¾å°„å‹ç½‘ç»œæ— é—­ç¯ï¼Œéé›¶å³çº¿è·¯
                    line_pairs.append((i, j))
        return line_pairs

    def forward(
            self,
            node_feat: torch.Tensor,
            adj: torch.Tensor,
            node_count: torch.Tensor,
            line_param: List[torch.Tensor]
    ) -> Tuple[torch.Tensor, List[torch.Tensor]]:
        """
        å‰å‘ä¼ æ’­ï¼šé¢„æµ‹å®Œæ•´èŠ‚ç‚¹ç”µå‹+çº¿è·¯æ½®æµï¼ˆè®ºæ–‡ğŸ”¶1-140å¾®è°ƒé€»è¾‘ï¼‰

        Args:
            node_feat: å¸¦ç”µå‹ç¼ºå¤±çš„è¾“å…¥èŠ‚ç‚¹ç‰¹å¾ï¼ˆB, N, 4ï¼‰
            adj: æ‹“æ‰‘é‚»æ¥çŸ©é˜µï¼ˆB, N, Nï¼‰
            node_count: æ¯ä¸ªåœºæ™¯çš„çœŸå®èŠ‚ç‚¹æ•°ï¼ˆB, ï¼‰
            line_param: çœŸå®çº¿è·¯å‚æ•°åˆ—è¡¨ï¼ˆBä¸ªå…ƒç´ ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(b, 4)ï¼Œåˆ—0=R, 1=Xï¼‰

        Returns:
            pred_node: è¡¥å…¨çš„èŠ‚ç‚¹ç‰¹å¾ï¼ˆB, N, 4ï¼‰
            pred_line: é¢„æµ‹çš„çº¿è·¯æ½®æµåˆ—è¡¨ï¼ˆBä¸ªå…ƒç´ ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(b, 4)ï¼ŒR/X=çœŸå®å€¼ï¼ŒP/Q=é¢„æµ‹å€¼ï¼‰
        """
        batch_size, max_node, _ = node_feat.shape
        pred_line = []

        # æ­¥éª¤1ï¼šè°ƒç”¨é¢„è®­ç»ƒéª¨å¹²ç½‘ç»œè¡¥å…¨èŠ‚ç‚¹ç‰¹å¾ï¼ˆç”µå‹ç¼ºå¤±ä¿®å¤ï¼‰
        pred_node = self.backbone(node_feat=node_feat, adj=adj, node_count=node_count)
        # æˆªæ–­å¡«å……èŠ‚ç‚¹ï¼ˆé¿å…æ— æ•ˆæ•°æ®å¹²æ‰°ï¼‰
        for b in range(batch_size):
            real_node = node_count[b].item()
            pred_node[b, real_node:, :] = 0.0

        # æ­¥éª¤2ï¼šé¢„æµ‹çº¿è·¯æ½®æµï¼ˆR/Xç”¨çœŸå®å€¼ï¼Œä»…P/Qä¸ºé¢„æµ‹å€¼ï¼‰
        for b in range(batch_size):
            real_node = node_count[b].item()
            # 2.1 è·å–å½“å‰åœºæ™¯çš„çº¿è·¯-èŠ‚ç‚¹å¯¹æ˜ å°„ï¼ˆb = real_node - 1ï¼‰
            line_pairs = self._get_line_node_mapping(adj[b], node_count[b])
            b_line = len(line_pairs)
            # 2.2 æå–å½“å‰åœºæ™¯çš„çœŸå®çº¿è·¯å‚æ•°ï¼ˆR/Xï¼‰å’Œéª¨å¹²ç½‘ç»œè¾“å‡ºçš„èŠ‚ç‚¹ç‰¹å¾
            line_param_b = line_param[b]  # (b_line, 4)
            node_feat_b = pred_node[b, :real_node, :]  # (real_node, d_model=64)

            # 2.3 çº¿è·¯çº§ç‰¹å¾èšåˆï¼ˆè¿æ¥èŠ‚ç‚¹ç‰¹å¾å¹³å‡ï¼‰
            line_feat = self.line_agg(node_feat_b.unsqueeze(0), line_pairs)  # (1, b_line, d_model)
            line_feat = line_feat.squeeze(0)  # (b_line, d_model)

            # 2.4 é¢„æµ‹çº¿è·¯æ½®æµï¼ˆ4ç»´ï¼šR, X, P, Qï¼‰
            line_pred_b = self.line_pred_head(line_feat)  # (b_line, 4)

            # 2.5 æ›¿æ¢R/Xä¸ºçœŸå®å€¼ï¼ˆä»…P/Qä¿ç•™é¢„æµ‹å€¼ï¼Œç¬¦åˆç”¨æˆ·éœ€æ±‚ï¼‰
            line_pred_b[:, 0] = line_param_b[:, 0]  # çœŸå®R
            line_pred_b[:, 1] = line_param_b[:, 1]  # çœŸå®X

            pred_line.append(line_pred_b)

        return pred_node, pred_line


def finetune_loop(
        model: GTransformerFinetune,
        train_loader: DataLoader,
        val_loader: DataLoader,
        loss_fn: PhysicsInformedLoss,
        optimizer: optim.Optimizer,
        epochs: int = 30,
        device: Optional[torch.device] = None,
        save_path: str = "./finetuned_weights.pth",
        unfreeze_epoch: int = 10,  # 10è½®åè§£å†»æ‰€æœ‰å±‚ï¼ˆè®ºæ–‡ğŸ”¶1-141å‚æ•°å¾®è°ƒç­–ç•¥ï¼‰
        patience: int = 5  # æ—©åœæœºåˆ¶ï¼šéªŒè¯æŸå¤±è¿ç»­5è½®ä¸ä¸‹é™åˆ™åœæ­¢
) -> None:
    """
    é…ç”µç½‘æ½®æµè®¡ç®—ä»»åŠ¡å¾®è°ƒå¾ªç¯ï¼ˆèšç„¦ç”µå‹ç¼ºå¤±åœºæ™¯ï¼‰
    è®ºæ–‡é€»è¾‘é€‚é…ï¼šé¢„è®­ç»ƒæƒé‡è¿ç§»+éƒ¨åˆ†å‚æ•°å†»ç»“+ç‰©ç†çº¦æŸç›‘ç£ï¼ˆğŸ”¶1-140ã€ğŸ”¶1-141ï¼‰

    Args:
        model: GTransformerFinetuneå®ä¾‹
        train_loader: è®­ç»ƒé›†DataLoaderï¼ˆ80ä¸ªåœºæ™¯ï¼‰
        val_loader: éªŒè¯é›†DataLoaderï¼ˆ15ä¸ªåœºæ™¯ï¼‰
        loss_fn: ç‰©ç†çŸ¥æƒ…æŸå¤±å‡½æ•°ï¼ˆç¡®ä¿é¢„æµ‹ç¬¦åˆç‰©ç†è§„å¾‹ï¼ŒğŸ”¶1-82ï¼‰
        optimizer: Adamä¼˜åŒ–å™¨ï¼ˆlr=5e-4ï¼Œå¼±äºé¢„è®­ç»ƒé¿å…ç ´åæƒé‡ï¼‰
        epochs: å¾®è°ƒè½®æ¬¡ï¼ˆé»˜è®¤30ï¼Œå°æ•°æ®é›†é€‚é…ï¼‰
        device: è®­ç»ƒè®¾å¤‡ï¼ˆè‡ªåŠ¨æ£€æµ‹cpu/cudaï¼‰
        save_path: æœ€ä¼˜å¾®è°ƒæƒé‡ä¿å­˜è·¯å¾„
        unfreeze_epoch: è§£å†»åº•å±‚å‚æ•°çš„è½®æ¬¡ï¼ˆé»˜è®¤10ï¼‰
        patience: æ—©åœæœºåˆ¶è€å¿ƒå€¼ï¼ˆé»˜è®¤5ï¼‰
    """
    # 1. è®¾å¤‡è‡ªåŠ¨æ£€æµ‹ä¸æ¨¡å‹éƒ¨ç½²
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    loss_fn.to(device)
    print(f"=== å¼€å§‹å¾®è°ƒ | è®¾å¤‡: {device} | æ€»è½®æ¬¡: {epochs} | è§£å†»è½®æ¬¡: {unfreeze_epoch} ===")

    # 2. åˆå§‹å‚æ•°å†»ç»“ï¼ˆä»…è®­ç»ƒé¡¶å±‚GTransformerå’Œçº¿è·¯é¢„æµ‹å¤´ï¼ŒğŸ”¶1-141ï¼‰
    def freeze_bottom_layers(freeze: bool):
        """å†»ç»“/è§£å†»GTransformerå‰1å±‚DyMPNå‚æ•°"""
        for layer_idx in range(min(1, model.backbone.n_layers)):
            dympn_layer = model.backbone.gtransformer_layers[layer_idx]["dympn"]
            for param in dympn_layer.parameters():
                param.requires_grad = not freeze

    freeze_bottom_layers(freeze=True)
    print("ğŸ”’ åˆå§‹çŠ¶æ€ï¼šå†»ç»“GTransformerå‰1å±‚DyMPNå‚æ•°ï¼Œä»…è®­ç»ƒé¡¶å±‚ä¸çº¿è·¯é¢„æµ‹å¤´")

    # 3. æ—©åœæœºåˆ¶åˆå§‹åŒ–
    best_val_loss = float("inf")
    patience_counter = 0

    # 4. å¾®è°ƒä¸»å¾ªç¯
    for epoch in range(1, epochs + 1):
        # 4.1 è½®æ¬¡å‰å¤„ç†ï¼šè§£å†»åº•å±‚å‚æ•°ï¼ˆè‹¥è¾¾åˆ°è§£å†»è½®æ¬¡ï¼‰
        if epoch == unfreeze_epoch:
            freeze_bottom_layers(freeze=False)
            print(f"ğŸ”“ Epoch {epoch}ï¼šè§£å†»æ‰€æœ‰å±‚å‚æ•°ï¼Œå…¨æ¨¡å‹å¾®è°ƒ")

        # -------------------------- è®­ç»ƒé˜¶æ®µ --------------------------
        model.train()
        train_metrics = {
            "total_loss": 0.0, "pred_loss": 0.0, "physics_loss": 0.0,
            "node_v_nrmse": 0.0, "line_p_nrmse": 0.0  # èŠ‚ç‚¹ç”µå‹ã€çº¿è·¯æœ‰åŠŸNRMSE
        }
        with tqdm(train_loader, desc=f"Epoch {epoch}/{epochs} (Train)", unit="batch") as pbar:
            for batch in pbar:
                # æ•°æ®ç§»è‡³è®¾å¤‡
                node_feat = batch["node_feat"].to(device)
                adj = batch["adj"].to(device)
                gt_node = batch["gt_node"].to(device)
                gt_line = batch["gt_line"].to(device)
                line_param = [lp.to(device) for lp in batch["line_param"]]
                node_count = batch["node_count"].to(device)
                batch_size = node_feat.shape[0]

                # å‰å‘ä¼ æ’­ï¼šé¢„æµ‹èŠ‚ç‚¹ç”µå‹+çº¿è·¯æ½®æµ
                pred_node, pred_line = model(
                    node_feat=node_feat,
                    adj=adj,
                    node_count=node_count,
                    line_param=line_param
                )

                # è®¡ç®—æŸå¤±ï¼ˆç‰©ç†çŸ¥æƒ…æŸå¤±ï¼ŒåŒé¢„è®­ç»ƒé€»è¾‘ï¼ŒğŸ”¶1-82ï¼‰
                total_loss, pred_loss, physics_loss = loss_fn(
                    pred_node=pred_node,
                    gt_node=gt_node,
                    pred_line=pred_line,
                    gt_line=gt_line,
                    adj=adj,
                    line_param=line_param,
                    node_count=node_count
                )

                # åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°
                optimizer.zero_grad()
                total_loss.backward()
                optimizer.step()

                # è®¡ç®—è®­ç»ƒæŒ‡æ ‡ï¼ˆè®ºæ–‡ğŸ”¶1-137ã€ğŸ”¶1-140è¯„ä¼°é€»è¾‘ï¼‰
                # èŠ‚ç‚¹ç”µå‹NRMSEï¼ˆä»…çœŸå®èŠ‚ç‚¹ï¼Œåˆ—2=ç”µå‹å¹…å€¼ï¼‰
                node_v_nrmse = 0.0
                # çº¿è·¯æœ‰åŠŸæ½®æµNRMSEï¼ˆä»…çœŸå®çº¿è·¯ï¼Œåˆ—2=æœ‰åŠŸï¼‰
                line_p_nrmse = 0.0
                for b in range(batch_size):
                    real_node = node_count[b].item()
                    real_line = len(pred_line[b])
                    # èŠ‚ç‚¹ç”µå‹NRMSE
                    pred_v = pred_node[b, :real_node, 2]
                    gt_v = gt_node[b, :real_node, 2]
                    node_v_nrmse += calc_nrmse(pred_v, gt_v) / batch_size
                    # çº¿è·¯æœ‰åŠŸNRMSE
                    pred_p = pred_line[b][:, 2]
                    gt_p = gt_line[b][:, 2]
                    line_p_nrmse += calc_nrmse(pred_p, gt_p) / batch_size

                # ç´¯è®¡è®­ç»ƒæŒ‡æ ‡
                train_metrics["total_loss"] += total_loss.item() * batch_size
                train_metrics["pred_loss"] += pred_loss.item() * batch_size
                train_metrics["physics_loss"] += physics_loss.item() * batch_size
                train_metrics["node_v_nrmse"] += node_v_nrmse * batch_size
                train_metrics["line_p_nrmse"] += line_p_nrmse * batch_size

                # è¿›åº¦æ¡æ›´æ–°
                pbar.set_postfix({
                    "æ€»æŸå¤±": f"{total_loss.item():.6f}",
                    "ç”µå‹NRMSE": f"{node_v_nrmse:.4f}",
                    "æœ‰åŠŸNRMSE": f"{line_p_nrmse:.4f}"
                })

        # è®­ç»ƒæŒ‡æ ‡å¹³å‡åŒ–ï¼ˆæŒ‰æ ·æœ¬æ•°ï¼‰
        train_sample_num = len(train_loader.dataset)
        train_metrics = {k: v / train_sample_num for k, v in train_metrics.items()}
        print(f"\nğŸ“Š Epoch {epoch} è®­ç»ƒæŒ‡æ ‡ï¼š")
        print(
            f"   æ€»æŸå¤±: {train_metrics['total_loss']:.6f} | é¢„æµ‹æŸå¤±: {train_metrics['pred_loss']:.6f} | ç‰©ç†æŸå¤±: {train_metrics['physics_loss']:.6f}")
        print(
            f"   èŠ‚ç‚¹ç”µå‹NRMSE: {train_metrics['node_v_nrmse']:.4f} | çº¿è·¯æœ‰åŠŸNRMSE: {train_metrics['line_p_nrmse']:.4f}")

        # -------------------------- éªŒè¯é˜¶æ®µ --------------------------
        model.eval()
        val_metrics = {
            "total_loss": 0.0, "pred_loss": 0.0, "physics_loss": 0.0,
            "node_v_nrmse": 0.0, "line_p_nrmse": 0.0,
            "power_balance_satisfaction": 0.0  # åŠŸç‡å¹³è¡¡çº¦æŸæ»¡è¶³ç‡ï¼ˆğŸ”¶1-137ï¼‰
        }
        with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒåŠ é€ŸéªŒè¯
            with tqdm(val_loader, desc=f"Epoch {epoch}/{epochs} (Val)", unit="batch") as pbar:
                for batch in pbar:
                    # æ•°æ®ç§»è‡³è®¾å¤‡
                    node_feat = batch["node_feat"].to(device)
                    adj = batch["adj"].to(device)
                    gt_node = batch["gt_node"].to(device)
                    gt_line = batch["gt_line"].to(device)
                    line_param = [lp.to(device) for lp in batch["line_param"]]
                    node_count = batch["node_count"].to(device)
                    batch_size = node_feat.shape[0]

                    # å‰å‘ä¼ æ’­
                    pred_node, pred_line = model(
                        node_feat=node_feat,
                        adj=adj,
                        node_count=node_count,
                        line_param=line_param
                    )

                    # è®¡ç®—éªŒè¯æŸå¤±
                    total_loss, pred_loss, physics_loss = loss_fn(
                        pred_node=pred_node,
                        gt_node=gt_node,
                        pred_line=pred_line,
                        gt_line=gt_line,
                        adj=adj,
                        line_param=line_param,
                        node_count=node_count
                    )

                    # è®¡ç®—éªŒè¯æŒ‡æ ‡
                    # 1. NRMSEæŒ‡æ ‡ï¼ˆåŒè®­ç»ƒé˜¶æ®µï¼‰
                    node_v_nrmse = 0.0
                    line_p_nrmse = 0.0
                    # 2. åŠŸç‡å¹³è¡¡çº¦æŸæ»¡è¶³ç‡ï¼ˆè¯¯å·®<2.5%æ ‡å¹ºå€¼ï¼ŒğŸ”¶1-137ï¼‰
                    power_balance_satisfaction = 0.0
                    for b in range(batch_size):
                        real_node = node_count[b].item()
                        real_line = len(pred_line[b])
                        # èŠ‚ç‚¹ç”µå‹NRMSE
                        pred_v = pred_node[b, :real_node, 2]
                        gt_v = gt_node[b, :real_node, 2]
                        node_v_nrmse += calc_nrmse(pred_v, gt_v) / batch_size
                        # çº¿è·¯æœ‰åŠŸNRMSE
                        pred_p = pred_line[b][:, 2]
                        gt_p = gt_line[b][:, 2]
                        line_p_nrmse += calc_nrmse(pred_p, gt_p) / batch_size
                        # åŠŸç‡å¹³è¡¡æ»¡è¶³ç‡ï¼ˆä»…éå¹³è¡¡èŠ‚ç‚¹ï¼‰
                        pred_p_inj = -pred_node[b, 1:real_node, 0]  # éå¹³è¡¡èŠ‚ç‚¹P_inj=-P_load
                        # è®¡ç®—çº¿è·¯æ½®æµå’Œï¼ˆç®€åŒ–ï¼šç”¨çœŸå®çº¿è·¯æ½®æµæ±‚å’Œï¼Œèšç„¦ç”µå‹é¢„æµ‹çš„æ»¡è¶³ç‡ï¼‰
                        gt_p_sum = torch.zeros(real_node, device=device)
                        line_pairs = model._get_line_node_mapping(adj[b], node_count[b])
                        for line_idx, (i, j) in enumerate(line_pairs):
                            p_ij = gt_line[b][line_idx, 2]
                            gt_p_sum[i] += p_ij
                            gt_p_sum[j] -= p_ij
                        # åŠŸç‡å¹³è¡¡è¯¯å·®ï¼ˆéå¹³è¡¡èŠ‚ç‚¹ï¼‰
                        p_err = torch.abs(pred_p_inj - gt_p_sum[1:real_node])
                        satisfaction = (p_err < 0.025).float().mean()  # 2.5%æ ‡å¹ºå€¼è¯¯å·®
                        power_balance_satisfaction += satisfaction.item() / batch_size

                    # ç´¯è®¡éªŒè¯æŒ‡æ ‡
                    val_metrics["total_loss"] += total_loss.item() * batch_size
                    val_metrics["pred_loss"] += pred_loss.item() * batch_size
                    val_metrics["physics_loss"] += physics_loss.item() * batch_size
                    val_metrics["node_v_nrmse"] += node_v_nrmse * batch_size
                    val_metrics["line_p_nrmse"] += line_p_nrmse * batch_size
                    val_metrics["power_balance_satisfaction"] += power_balance_satisfaction * batch_size

                    # è¿›åº¦æ¡æ›´æ–°
                    pbar.set_postfix({
                        "valæ€»æŸå¤±": f"{total_loss.item():.6f}",
                        "valç”µå‹NRMSE": f"{node_v_nrmse:.4f}",
                        "åŠŸç‡æ»¡è¶³ç‡": f"{power_balance_satisfaction:.2%}"
                    })

        # éªŒè¯æŒ‡æ ‡å¹³å‡åŒ–
        val_sample_num = len(val_loader.dataset)
        val_metrics = {k: v / val_sample_num for k, v in val_metrics.items()}
        print(f"ğŸ“Š Epoch {epoch} éªŒè¯æŒ‡æ ‡ï¼š")
        print(
            f"   æ€»æŸå¤±: {val_metrics['total_loss']:.6f} | é¢„æµ‹æŸå¤±: {val_metrics['pred_loss']:.6f} | ç‰©ç†æŸå¤±: {val_metrics['physics_loss']:.6f}")
        print(f"   èŠ‚ç‚¹ç”µå‹NRMSE: {val_metrics['node_v_nrmse']:.4f} | çº¿è·¯æœ‰åŠŸNRMSE: {val_metrics['line_p_nrmse']:.4f}")
        print(f"   åŠŸç‡å¹³è¡¡çº¦æŸæ»¡è¶³ç‡: {val_metrics['power_balance_satisfaction']:.2%}")

        # -------------------------- æ—©åœæœºåˆ¶ä¸æƒé‡ä¿å­˜ --------------------------
        # ä¿å­˜éªŒè¯æŸå¤±æœ€ä½çš„æ¨¡å‹ï¼ˆè®ºæ–‡ğŸ”¶1-140æœ€ä¼˜æ¨¡å‹é€‰æ‹©é€»è¾‘ï¼‰
        if val_metrics["total_loss"] < best_val_loss:
            best_val_loss = val_metrics["total_loss"]
            patience_counter = 0
            torch.save(model.state_dict(), save_path)
            print(f"âœ… ä¿å­˜æœ€ä¼˜æ¨¡å‹è‡³: {save_path}ï¼ˆéªŒè¯æŸå¤±: {best_val_loss:.6f}ï¼‰")
        else:
            patience_counter += 1
            print(f"âš ï¸  éªŒè¯æŸå¤±æœªä¸‹é™ï¼ˆè¿ç»­{patience_counter}/{patience}è½®ï¼‰")
            # æ—©åœè§¦å‘
            if patience_counter >= patience:
                print(f"ğŸ›‘ æ—©åœæœºåˆ¶è§¦å‘ï¼šéªŒè¯æŸå¤±è¿ç»­{patience}è½®ä¸ä¸‹é™ï¼Œåœæ­¢å¾®è°ƒ")
                break

    # -------------------------- å¾®è°ƒç»“æŸï¼šæµ‹è¯•é›†è¯„ä¼° --------------------------
    # ä»éªŒè¯é›†æ‹†åˆ†æµ‹è¯•é›†ï¼ˆ5ä¸ªåœºæ™¯ï¼ŒğŸ”¶1-140æµ‹è¯•é€»è¾‘ï¼‰
    test_indices = np.random.choice(len(val_loader.dataset), size=5, replace=False)
    test_dataset = Subset(val_loader.dataset, test_indices)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)

    model.load_state_dict(torch.load(save_path))  # åŠ è½½æœ€ä¼˜æƒé‡
    model.eval()
    test_metrics = {
        "node_v_nrmse": 0.0, "line_p_nrmse": 0.0,
        "power_balance_satisfaction": 0.0, "voltage_satisfaction": 0.0  # ç”µå‹çº¦æŸæ»¡è¶³ç‡
    }
    with torch.no_grad():
        print("\n=== å¾®è°ƒç»“æŸï¼šæµ‹è¯•é›†è¯„ä¼°ï¼ˆ5ä¸ªåœºæ™¯ï¼‰ ===")
        for batch_idx, batch in enumerate(test_loader, 1):
            node_feat = batch["node_feat"].to(device)
            adj = batch["adj"].to(device)
            gt_node = batch["gt_node"].to(device)
            gt_line = batch["gt_line"].to(device)
            line_param = [lp.to(device) for lp in batch["line_param"]]
            node_count = batch["node_count"].to(device)
            real_node = node_count[0].item()

            # å‰å‘ä¼ æ’­
            pred_node, pred_line = model(
                node_feat=node_feat,
                adj=adj,
                node_count=node_count,
                line_param=line_param
            )

            # è®¡ç®—æµ‹è¯•æŒ‡æ ‡
            # 1. èŠ‚ç‚¹ç”µå‹NRMSE
            pred_v = pred_node[0, :real_node, 2]
            gt_v = gt_node[0, :real_node, 2]
            node_v_nrmse = calc_nrmse(pred_v, gt_v)
            # 2. çº¿è·¯æœ‰åŠŸNRMSE
            pred_p = pred_line[0][:, 2]
            gt_p = gt_line[0][:, 2]
            line_p_nrmse = calc_nrmse(pred_p, gt_p)
            # 3. åŠŸç‡å¹³è¡¡æ»¡è¶³ç‡
            pred_p_inj = -pred_node[0, 1:real_node, 0]
            gt_p_sum = torch.zeros(real_node, device=device)
            line_pairs = model._get_line_node_mapping(adj[0], node_count[0])
            for line_idx, (i, j) in enumerate(line_pairs):
                p_ij = gt_line[0][line_idx, 2]
                gt_p_sum[i] += p_ij
                gt_p_sum[j] -= p_ij
            p_err = torch.abs(pred_p_inj - gt_p_sum[1:real_node])
            power_satisfaction = (p_err < 0.025).float().mean().item()
            # 4. ç”µå‹çº¦æŸæ»¡è¶³ç‡ï¼ˆæ ‡å¹ºå€¼0.95~1.05ï¼ŒğŸ”¶1-137ï¼‰
            voltage_satisfaction = ((pred_v >= 0.95) & (pred_v <= 1.05)).float().mean().item()

            # ç´¯è®¡æµ‹è¯•æŒ‡æ ‡
            test_metrics["node_v_nrmse"] += node_v_nrmse / 5
            test_metrics["line_p_nrmse"] += line_p_nrmse / 5
            test_metrics["power_balance_satisfaction"] += power_satisfaction / 5
            test_metrics["voltage_satisfaction"] += voltage_satisfaction / 5

            print(f"åœºæ™¯{batch_idx}ï¼š")
            print(f"  èŠ‚ç‚¹ç”µå‹NRMSE: {node_v_nrmse:.4f} | çº¿è·¯æœ‰åŠŸNRMSE: {line_p_nrmse:.4f}")
            print(f"  åŠŸç‡å¹³è¡¡æ»¡è¶³ç‡: {power_satisfaction:.2%} | ç”µå‹çº¦æŸæ»¡è¶³ç‡: {voltage_satisfaction:.2%}")

    # æ‰“å°æœ€ç»ˆæµ‹è¯•æŒ‡æ ‡
    print("\n=== æœ€ç»ˆæµ‹è¯•æŒ‡æ ‡ï¼ˆ5ä¸ªåœºæ™¯å¹³å‡ï¼‰ ===")
    print(f"èŠ‚ç‚¹ç”µå‹NRMSE: {test_metrics['node_v_nrmse']:.4f}")
    print(f"çº¿è·¯æœ‰åŠŸNRMSE: {test_metrics['line_p_nrmse']:.4f}")
    print(f"åŠŸç‡å¹³è¡¡çº¦æŸæ»¡è¶³ç‡: {test_metrics['power_balance_satisfaction']:.2%}")
    print(f"ç”µå‹çº¦æŸæ»¡è¶³ç‡: {test_metrics['voltage_satisfaction']:.2%}")
    print(f"\nğŸ‰ å¾®è°ƒå®Œæˆï¼æœ€ä¼˜æ¨¡å‹å·²ä¿å­˜è‡³: {save_path}")

# -------------------------- å¾®è°ƒå¯åŠ¨ç¤ºä¾‹ï¼ˆå®Œæ•´æµç¨‹ï¼‰ --------------------------
# if __name__ == "__main__":
#     """
#     ç¤ºä¾‹ï¼šä»æ•°æ®æ‹†åˆ†åˆ°å¾®è°ƒå¯åŠ¨çš„å®Œæ•´æµç¨‹ï¼ˆé€‚é…ç”¨æˆ·20-50èŠ‚ç‚¹è¾å°„å‹é…ç”µç½‘ï¼‰
#     ä¾èµ–æ¨¡å—ï¼šdata_loaderï¼ˆSceneDatasetï¼‰ã€pretrainingï¼ˆGTransformerPretrainï¼‰ã€utilsï¼ˆè¯„ä¼°æŒ‡æ ‡ï¼‰
#     """
#     # 1. å¯¼å…¥ä¾èµ–æ¨¡å—
#     from data_loader import SceneDataset, get_data_loader
#     import numpy as np
#
#     # 2. é…ç½®å¾®è°ƒå‚æ•°ï¼ˆè®ºæ–‡ğŸ”¶1-128ã€ğŸ”¶1-140å‚æ•°é€‚é…ï¼‰
#     FINETUNE_CONFIG = {
#         "data_root": "./Dataset",               # ç”¨æˆ·æ•°æ®é›†è·¯å¾„
#         "mask_ratio": 0.3,                      # ç”µå‹ç¼ºå¤±æ¯”ä¾‹ï¼ˆåŒé¢„è®­ç»ƒï¼‰
#         "pretrain_path": "./pretrained_weights.pth",  # é¢„è®­ç»ƒæƒé‡è·¯å¾„
#         "save_path": "./finetuned_weights.pth", # å¾®è°ƒæƒé‡ä¿å­˜è·¯å¾„
#         "batch_size": 4,                        # å¾®è°ƒBatchï¼ˆå°äºé¢„è®­ç»ƒï¼Œé¿å…è¿‡æ‹Ÿåˆï¼‰
#         "epochs": 30,                           # å¾®è°ƒè½®æ¬¡
#         "lr": 5e-4,                             # å­¦ä¹ ç‡ï¼ˆé¢„è®­ç»ƒçš„1/2ï¼Œä¿æŠ¤é¢„è®­ç»ƒæƒé‡ï¼‰
#         "unfreeze_epoch": 10,                   # è§£å†»åº•å±‚å‚æ•°è½®æ¬¡
#         "patience": 5,                          # æ—©åœè€å¿ƒå€¼
#         "d_in": 4,                              # è¾“å…¥ç‰¹å¾ç»´åº¦
#         "d_model": 64,                          # åµŒå…¥ç»´åº¦ï¼ˆåŒé¢„è®­ç»ƒï¼‰
#         "n_heads": 4,                           # æ³¨æ„åŠ›å¤´æ•°ï¼ˆåŒé¢„è®­ç»ƒï¼‰
#         "n_layers": 2                           # GTransformerå±‚æ•°ï¼ˆåŒé¢„è®­ç»ƒï¼‰
#     }
#
#     # 3. æ•°æ®é›†åŠ è½½ä¸æ‹†åˆ†ï¼ˆ100åœºæ™¯ï¼š80è®­ç»ƒ+15éªŒè¯+5æµ‹è¯•ï¼‰
#     print("=== åŠ è½½å¹¶æ‹†åˆ†æ•°æ®é›† ===")
#     # 3.1 åŠ è½½å®Œæ•´æ•°æ®é›†
#     full_dataset = SceneDataset(
#         data_root=FINETUNE_CONFIG["data_root"],
#         mask_ratio=FINETUNE_CONFIG["mask_ratio"]
#     )
#     # 3.2 éšæœºæ‹†åˆ†ç´¢å¼•ï¼ˆå›ºå®šç§å­ç¡®ä¿å¯å¤ç°ï¼‰
#     np.random.seed(42)
#     total_scenes = len(full_dataset)  # 100
#     indices = np.random.permutation(total_scenes)
#     train_indices = indices[:80]     # 80è®­ç»ƒ
#     val_indices = indices[80:95]     # 15éªŒè¯
#     # 3.3 åˆ›å»ºè®­ç»ƒ/éªŒè¯æ•°æ®é›†ä¸DataLoader
#     train_dataset = Subset(full_dataset, train_indices)
#     val_dataset = Subset(full_dataset, val_indices)
#     train_loader = get_data_loader(
#         dataset=train_dataset,
#         batch_size=FINETUNE_CONFIG["batch_size"],
#         shuffle=True,
#         num_workers=2
#     )
#     val_loader = get_data_loader(
#         dataset=val_dataset,
#         batch_size=FINETUNE_CONFIG["batch_size"],
#         shuffle=False,
#         num_workers=1
#     )
#     print(f"æ•°æ®é›†æ‹†åˆ†å®Œæˆï¼šè®­ç»ƒ{len(train_dataset)}ä¸ªåœºæ™¯ | éªŒè¯{len(val_dataset)}ä¸ªåœºæ™¯ | æµ‹è¯•5ä¸ªåœºæ™¯ï¼ˆä»éªŒè¯é›†æ‹†åˆ†ï¼‰")
#
#     # 4. åˆå§‹åŒ–å¾®è°ƒæ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
#     print("\n=== åˆå§‹åŒ–å¾®è°ƒç»„ä»¶ ===")
#     # 4.1 å¾®è°ƒæ¨¡å‹ï¼ˆåŠ è½½é¢„è®­ç»ƒæƒé‡ï¼‰
#     model = GTransformerFinetune(
#         pretrain_path=FINETUNE_CONFIG["pretrain_path"],
#         d_in=FINETUNE_CONFIG["d_in"],
#         d_model=FINETUNE_CONFIG["d_model"],
#         n_heads=FINETUNE_CONFIG["n_heads"],
#         n_layers=FINETUNE_CONFIG["n_layers"]
#     )
#     # 4.2 ç‰©ç†çŸ¥æƒ…æŸå¤±å‡½æ•°ï¼ˆÎ»=0.5ï¼ŒåŒé¢„è®­ç»ƒï¼‰
#     loss_fn = PhysicsInformedLoss(lambda_=0.5)
#     # 4.3 Adamä¼˜åŒ–å™¨ï¼ˆlr=5e-4ï¼Œè®ºæ–‡æ¨èï¼‰
#     optimizer = optim.Adam(
#         model.parameters(),
#         lr=FINETUNE_CONFIG["lr"],
#         weight_decay=1e-5  # è½»å¾®æƒé‡è¡°å‡ï¼Œç¼“è§£è¿‡æ‹Ÿåˆ
#     )
#     print(f"æ¨¡å‹å‚æ•°æ€»æ•°ï¼š{sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
#
#     # 5. å¯åŠ¨å¾®è°ƒ
#     print("\n=== å¯åŠ¨å¾®è°ƒæµç¨‹ ===")
#     finetune_loop(
#         model=model,
#         train_loader=train_loader,
#         val_loader=val_loader,
#         loss_fn=loss_fn,
#         optimizer=optimizer,
#         epochs=FINETUNE_CONFIG["epochs"],
#         save_path=FINETUNE_CONFIG["save_path"],
#         unfreeze_epoch=FINETUNE_CONFIG["unfreeze_epoch"],
#         patience=FINETUNE_CONFIG["patience"]
#     )